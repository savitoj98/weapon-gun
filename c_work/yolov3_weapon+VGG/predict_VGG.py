# USAGE
# python predict.py --image dataset/evaluation/Egg/3_137.jpg 

# import the necessary packages
from keras.models import load_model
from pyimagesearch import config
import numpy as np
#import argparse
import imutils
import cv2










def VGG_inference(image,model):
    
    output = image.copy()
    output = imutils.resize(output, width=400)
    
    # our model was trained on RGB ordered images but OpenCV represents
    # images in BGR order, so swap the channels, and then resize to
    # 224x224 (the input dimensions for VGG16)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    print('Image size fed into VGG: ',image.shape)
    cv2.imwrite('croped_1.png',image)
    image = cv2.resize(image, (224, 224))
    cv2.imwrite('resized_img1.png',image)
    exit()
    # convert the image to a floating point data type and perform mean
    # subtraction
    image = image.astype("float32")
    mean = np.array([123.68, 116.779, 103.939][::1], dtype="float32")
    image -= mean
    
    # load the trained model from disk
#    print("[INFO] loading model...")
#    model = load_model("VGG_model/weapon.model")
    
    # pass the image through the network to obtain our predictions
    preds = model.predict(np.expand_dims(image, axis=0))[0]
    i = np.argmax(preds)
    #print("@@@@@@@@@@@@@@@@@@@@@@@",i)
    label = config.CLASSES[i]
    
    # draw the prediction on the output image
    text = "{}: {:.2f}%".format(label, preds[i] * 100)
    cv2.putText(output, text, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
    	(0, 255, 0), 2)
    
    # show the output image
#    cv2.imshow("Output", output)
#    cv2.waitKey(0)
#    cv2.destroyAllWindows()
    return i






















## construct the argument parser and parse the arguments
#ap = argparse.ArgumentParser()
#ap.add_argument("-i", "--image", type=str, required=True,
#	help="path to our input image")
#args = vars(ap.parse_args())
#
## load the input image and then clone it so we can draw on it later
#image = cv2.imread(args["image"])
#output = image.copy()
#output = imutils.resize(output, width=400)
#
## our model was trained on RGB ordered images but OpenCV represents
## images in BGR order, so swap the channels, and then resize to
## 224x224 (the input dimensions for VGG16)
#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
#image = cv2.resize(image, (224, 224))
#
## convert the image to a floating point data type and perform mean
## subtraction
#image = image.astype("float32")
#mean = np.array([123.68, 116.779, 103.939][::1], dtype="float32")
#image -= mean
#
## load the trained model from disk
#print("[INFO] loading model...")
#model = load_model(config.MODEL_PATH)
#
## pass the image through the network to obtain our predictions
#preds = model.predict(np.expand_dims(image, axis=0))[0]
#i = np.argmax(preds)
#label = config.CLASSES[i]
#
## draw the prediction on the output image
#text = "{}: {:.2f}%".format(label, preds[i] * 100)
#cv2.putText(output, text, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
#	(0, 255, 0), 2)
#
## show the output image
#cv2.imshow("Output", output)
#cv2.waitKey(0)
#cv2.destroyAllWindows()
